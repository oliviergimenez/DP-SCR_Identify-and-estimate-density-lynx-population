{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a108a3",
   "metadata": {},
   "source": [
    "# Managing a local MegaDetector video batch\n",
    "\n",
    "This notebook represents an interactive process for running MegaDetector on large batches of videos, including typical and optional postprocessing steps.\n",
    "\n",
    "This notebook is auto-generated from manage_video_batch.py (a cell-delimited .py file that is used the same way, typically in Spyder or VS Code).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a7232",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from md_utils import path_utils\n",
    "from detection import video_utils\n",
    "\n",
    "input_folder = '/datadrive/data'\n",
    "output_folder_base = '/datadrive/frames'\n",
    "\n",
    "assert os.path.isdir(input_folder)\n",
    "os.makedirs(output_folder_base,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4cc514",
   "metadata": {},
   "source": [
    "## Split videos into frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(input_folder)\n",
    "os.makedirs(output_folder_base,exist_ok=True)\n",
    "\n",
    "recursive = True\n",
    "overwrite = True\n",
    "n_threads = 4\n",
    "every_n_frames = 10\n",
    "\n",
    "frame_filenames_by_video,fs_by_video,video_filenames = \\\n",
    "    video_utils.video_folder_to_frames(input_folder=input_folder,\n",
    "                                                              output_folder_base=output_folder_base,\n",
    "                                                              recursive=recursive,\n",
    "                                                              overwrite=overwrite,\n",
    "                                                              n_threads=n_threads,\n",
    "                                                              every_n_frames=every_n_frames,\n",
    "                                                              parallelization_uses_threads=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b9176",
   "metadata": {},
   "source": [
    "## List frame files, break into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "frame_files = path_utils.find_images(output_folder_base,True)\n",
    "frame_files = [s.replace('\\\\','/') for s in frame_files]\n",
    "print('Enumerated {} total frames'.format(len(frame_files)))\n",
    "\n",
    "# Find unique (relative) folders\n",
    "folder_to_frame_files = defaultdict(list)\n",
    "\n",
    "# fn = frame_files[0]\n",
    "for fn in frame_files:\n",
    "    folder_name = os.path.dirname(fn)\n",
    "    folder_name = os.path.relpath(folder_name,output_folder_base)\n",
    "    folder_to_frame_files[folder_name].append(fn)\n",
    "\n",
    "print('Found {} folders for {} files'.format(len(folder_to_frame_files),len(frame_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff112e5",
   "metadata": {},
   "source": [
    "## List videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14331e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filenames = video_utils.find_videos(input_folder,recursive=True)\n",
    "video_filenames = [os.path.relpath(fn,input_folder) for fn in video_filenames]\n",
    "print('Input folder contains {} videos'.format(len(video_filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f3811",
   "metadata": {},
   "source": [
    "## Check for videos that are missing entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74dbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(folder_to_frame_files.keys())[0]\n",
    "# video_filenames[0]\n",
    "\n",
    "missing_videos = []\n",
    "\n",
    "# fn = video_filenames[0]\n",
    "for relative_fn in video_filenames:\n",
    "    if relative_fn not in folder_to_frame_files:\n",
    "        missing_videos.append(relative_fn)\n",
    "\n",
    "print('{} of {} folders are missing frames entirely'.format(len(missing_videos),\n",
    "                                                            len(video_filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211437b",
   "metadata": {},
   "source": [
    "## Check for videos with very few frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frames_for_valid_video = 10\n",
    "\n",
    "low_frame_videos = []\n",
    "\n",
    "for folder_name in folder_to_frame_files.keys():\n",
    "    frame_files = folder_to_frame_files[folder_name]\n",
    "    if len(frame_files) < min_frames_for_valid_video:\n",
    "        low_frame_videos.append(folder_name)\n",
    "\n",
    "print('{} of {} folders have fewer than {} frames'.format(\n",
    "    len(low_frame_videos),len(video_filenames),min_frames_for_valid_video))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17817e",
   "metadata": {},
   "source": [
    "## Print the list of videos that are problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Videos that could not be decoded:\\n')\n",
    "\n",
    "for fn in missing_videos:\n",
    "    print(fn)\n",
    "\n",
    "print('\\nVideos with fewer than {} decoded frames:\\n'.format(min_frames_for_valid_video))\n",
    "\n",
    "for fn in low_frame_videos:\n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1967eecf",
   "metadata": {},
   "source": [
    "## Process images like we would for any other camera trap job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...typically using manage_local_batch.py or manage_local_batch.ipynb, but do this however\n",
    "# you like, as long as you get a results file at the end.\n",
    "#\n",
    "# If you do RDE, remember to use the second folder from the bottom, rather than the\n",
    "# bottom-most folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db85817",
   "metadata": {},
   "source": [
    "## Convert frame results to video results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection.video_utils import frame_results_to_video_results\n",
    "\n",
    "filtered_output_filename = '/results/organization/stuff.json'\n",
    "video_output_filename = filtered_output_filename.replace('.json','_aggregated.json')\n",
    "frame_results_to_video_results(filtered_output_filename,video_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849b05c",
   "metadata": {},
   "source": [
    "## Confirm that the videos in the .json file are what we expect them to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(video_output_filename,'r') as f:\n",
    "    video_results = json.load(f)\n",
    "\n",
    "video_filenames_set = set(video_filenames)\n",
    "\n",
    "filenames_in_video_results_set = set([im['file'] for im in video_results['images']])\n",
    "\n",
    "for fn in filenames_in_video_results_set:\n",
    "    assert fn in video_filenames_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92582d15",
   "metadata": {},
   "source": [
    "## Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908fa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    pass\n",
    "\n",
    "    #%% Render one or more sample videos...\n",
    "\n",
    "    # ...while we still have the frames and detections around\n",
    "\n",
    "    ## Imports\n",
    "\n",
    "    from md_visualization import visualize_detector_output\n",
    "    from detection.video_utils import frames_to_video\n",
    "\n",
    "\n",
    "    ## Constants and paths\n",
    "\n",
    "    confidence_threshold = 0.2\n",
    "    input_fs = 30\n",
    "\n",
    "    filtered_output_filename = '/a/b/c/blah_detections.filtered_rde_0.150_0.850_10_1.000.json'\n",
    "    video_fn_relative = '4.10cam6/IMG_0022.MP4'\n",
    "    output_video_base = os.path.expanduser('~/tmp/video_preview')\n",
    "\n",
    "\n",
    "    ## Filename handling\n",
    "\n",
    "    video_fn_relative = video_fn_relative.replace('\\\\','/')\n",
    "    video_fn_flat = video_fn_relative.replace('/','#')\n",
    "    video_name = os.path.splitext(video_fn_flat)[0]\n",
    "    output_video = os.path.join(output_video_base,'{}_detections.mp4'.format(video_name))\n",
    "    output_fs = input_fs / every_n_frames\n",
    "\n",
    "    rendered_detections_folder = os.path.join(output_video_base,'rendered_detections_{}'.format(video_name))\n",
    "    os.makedirs(rendered_detections_folder,exist_ok=True)\n",
    "\n",
    "\n",
    "    ## Find frames corresponding to this video\n",
    "\n",
    "    with open(filtered_output_filename,'r') as f:\n",
    "        frame_results = json.load(f)\n",
    "\n",
    "    frame_results_this_video = []\n",
    "\n",
    "    # im = frame_results['images'][0]\n",
    "    for im in frame_results['images']:\n",
    "        if im['file'].replace('\\\\','/').startswith(video_fn_relative):\n",
    "            frame_results_this_video.append(im)\n",
    "\n",
    "    assert len(frame_results_this_video) > 0, \\\n",
    "        'No frame results matched {}'.format(video_fn_relative)\n",
    "    print('Found {} matching frame results'.format(len(frame_results_this_video)))\n",
    "\n",
    "    frame_results['images'] = frame_results_this_video\n",
    "\n",
    "    frames_json = os.path.join(rendered_detections_folder,video_fn_flat + '.json')\n",
    "\n",
    "    with open(frames_json,'w') as f:\n",
    "        json.dump(frame_results,f,indent=1)\n",
    "\n",
    "\n",
    "    ## Render detections on those frames\n",
    "\n",
    "    detected_frame_files = visualize_detector_output.visualize_detector_output(\n",
    "        detector_output_path=frames_json,\n",
    "        out_dir=rendered_detections_folder,\n",
    "        images_dir=output_folder_base,\n",
    "        confidence_threshold=confidence_threshold,\n",
    "        preserve_path_structure=True,\n",
    "        output_image_width=-1)\n",
    "\n",
    "\n",
    "    ## Render the output video\n",
    "\n",
    "    frames_to_video(detected_frame_files, output_fs, output_video, codec_spec='h264')\n",
    "\n",
    "    # from md_utils.path_utils import open_file; open_file(output_video)\n",
    "\n",
    "\n",
    "    #%% Test a possibly-broken video\n",
    "\n",
    "    fn = '/datadrive/tmp/video.AVI'\n",
    "\n",
    "    fs = video_utils.get_video_fs(fn)\n",
    "    print(fs)\n",
    "\n",
    "    tmpfolder = '/home/user/tmp/frametmp'\n",
    "    os.makedirs(tmpfolder,exist_ok=True)\n",
    "\n",
    "    video_utils.video_to_frames(fn, tmpfolder, verbose=True, every_n_frames=10)\n",
    "\n",
    "\n",
    "    #%% List videos in a folder\n",
    "\n",
    "    input_folder = '/datadrive/tmp/organization/data'\n",
    "    video_filenames = video_utils.find_videos(input_folder,recursive=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
