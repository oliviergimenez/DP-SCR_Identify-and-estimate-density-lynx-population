{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f68df0-4627-42a4-beb5-1f47b13d3133",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LynxDataset tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d346f0e6-79bb-4d10-bdc6-06366510f498",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup notebook and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901468f-6a87-4bf8-a666-b1adc20b8890",
   "metadata": {},
   "source": [
    "For now, I tested everything in pytorch 2.0.1.\n",
    "\n",
    "I had to install albumentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab73dfe-f60f-443f-9c67-34ca303a5c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Allow reloading of libraries without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8083f535-104d-4500-a7a6-037e8cb2b614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset import LynxDataset\n",
    "dataset_csv = '/gpfsscratch/rech/ads/commun/datasets/extracted/lynx_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b8888-5b2b-4634-9ad4-3382b433f165",
   "metadata": {},
   "source": [
    "## Accessing the elements of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58295a81-df0b-4332-9133-618481d9bc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of the dataset\n",
    "dataset = LynxDataset(dataset_csv=dataset_csv, loader=\"pil\")\n",
    "\n",
    "input, output = dataset[0]  # Example for getting the first item\n",
    "\n",
    "# Accessing data\n",
    "image = input['image']\n",
    "lynx_id = output['lynx_id']\n",
    "# Access other metadata from input as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a32bf-cc49-4263-aaa5-2a735c4358d4",
   "metadata": {},
   "source": [
    "## Iterating through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2082abd-8c5a-4378-befb-d6c00fc078a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  15%|█▌        | 503/3330 [00:32<04:30, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 502: image file is truncated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset:  61%|██████    | 2033/3330 [02:04<00:51, 24.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 2032: image file is truncated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 3330/3330 [03:09<00:00, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset iteration completed with checks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Using tqdm to add a progress bar to the loop\n",
    "for idx in tqdm(range(len(dataset)), desc=\"Processing dataset\"):\n",
    "    try:\n",
    "        # Attempt to load the image data and other information\n",
    "        input_dict, output_dict = dataset[idx]\n",
    "\n",
    "        # Access key elements to ensure they're loaded correctly\n",
    "        _ = input_dict['image']\n",
    "        _ = output_dict['lynx_id']\n",
    "        # Add checks for other elements if necessary\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {idx}: {e}\")\n",
    "        # Continue to the next iteration after logging the error\n",
    "        continue\n",
    "\n",
    "print(\"Dataset iteration completed with checks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620cb0ac-7c3f-41b1-8c70-04729ad3739d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparing loading with pil vs opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "108fd9b9-dd78-47c5-8a79-a49e1eec1ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken with PIL: 7.331503629684448 seconds\n",
      "Time taken with OpenCV: 9.016743421554565 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "dataset_pil = LynxDataset(dataset_csv=dataset_csv, loader='pil')  # Use PIL\n",
    "dataset_opencv = LynxDataset(dataset_csv=dataset_csv, loader='opencv')  # Use OpenCV\n",
    "\n",
    "def measure_performance(dataset, num_samples=100):\n",
    "    start_time = time.time()\n",
    "    for i in range(num_samples):\n",
    "        _ = dataset[i]\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Measure performance\n",
    "\n",
    "_ = measure_performance(dataset_pil) #just for fairness, avoid cache difference...\n",
    "pil_time = measure_performance(dataset_pil)\n",
    "opencv_time = measure_performance(dataset_opencv)\n",
    "\n",
    "print(f\"Time taken with PIL: {pil_time} seconds\")\n",
    "print(f\"Time taken with OpenCV: {opencv_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663cc38d-ba84-4537-b13b-e30d25fc50d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.0.1_py3.10.12",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.0.1_py3.10.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
